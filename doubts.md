# Questions

## LLM
1. Does prefill phase include first token generation?
2. What is request rate in LLM serving?
3. Topics -> Prefix-caching, chunked prefill, infligh batching
4. Parallelism -> PP, TP

## Device
1. GPUs and architectures
2. Nvidia GPUs

## DeepLearning
1. TensorRT 

## General
